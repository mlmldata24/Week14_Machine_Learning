{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa78574b-d9db-4449-b800-0aa9b1460993",
   "metadata": {},
   "source": [
    "## Linear Regression as a Machine Learning Model\n",
    "In this notebook, we will revisit linear regression and consider implementing it as a machine learning model.\n",
    "\n",
    "### Import modules\n",
    "Begin by importing the modules to be used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5b778-fdba-4ce4-b322-aa326262b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90628864-f7fb-42f5-bf90-a66254d0f7e9",
   "metadata": {},
   "source": [
    "### Linear Regression Revisited\n",
    "In previous lectures, we used regression to fit linear curves to our data.\n",
    "\n",
    "For example, consider the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d2134-a537-4c17-9ce3-4ca1cf9e608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('linear_scatter.csv',delimiter=',')\n",
    "x = data[:,0]\n",
    "y = data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef5e95-f6d2-4364-b495-93b2dc9cec55",
   "metadata": {},
   "source": [
    "Perhaps this data pertains to kelp canopy height depending on weeks in the season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dcd8bb-ad5a-4214-b464-ce30046b5e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,'k.')\n",
    "plt.xlabel('x (time since June 1, weeks)')\n",
    "plt.ylabel('y (canopy height, m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae2a10e-d0fb-4c01-bec8-dc698fa10853",
   "metadata": {},
   "source": [
    "We can fit a polynomial to this data using numpy as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41159f-45e6-4431-ad23-9920ce5da3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.polyfit(x,y,deg=1)\n",
    "slope_fit = p[0]\n",
    "intercept_fit = p[1]\n",
    "print(intercept_fit, slope_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6c145-d663-4a2f-aba4-c8b38e02f1f6",
   "metadata": {},
   "source": [
    "This slope and intercept defines a growth rate through the season, We can plot the model on an independent x-axis as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec837bb-55dc-44a3-b65c-546bdaa6990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_x = np.arange(0,10,0.1)\n",
    "model_y = np.poly1d(p)\n",
    "fit_y = model_y(ordered_x)\n",
    "\n",
    "plt.plot(x,y,'k.',label='data')\n",
    "plt.plot(ordered_x, fit_y,'b-',label='model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9baac5e-7c41-47ab-a4d0-3a0bc3f976ce",
   "metadata": {},
   "source": [
    "In this process, we minimized the error between the points and the line to find the best estimates of the slope $m$ and the slope $b$. We could write this as a cost function as\n",
    "$$\n",
    " J = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (y_{data}(i) - y_{model}(i))^2}\n",
    "$$\n",
    "and code it up in numpy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b68e0-2883-472c-8930-8a57063debc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(y_data, y_modeled):\n",
    "    # RMSE\n",
    "    N = np.size(y_data)\n",
    "    squared_error = (1/N)*np.sum((y_data-y_modeled)**2)\n",
    "    return(np.sqrt(squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82d074-249e-46dc-8a8a-69d24e9eaff4",
   "metadata": {},
   "source": [
    "Using the above cose function, we can compute the \"error space\" -- the cost between data and model for a range of the parameters $m$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f0463-f31c-429f-aa01-eccd14ddfe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_space = np.linspace(-20,50,100)\n",
    "slope_space = np.linspace(1,12,100)\n",
    "I, S = np.meshgrid(intercept_space, slope_space)\n",
    "Error = np.zeros((100,100))\n",
    "\n",
    "# fill in the error matrix\n",
    "for row in range(np.shape(I)[0]):\n",
    "    for col in range(np.shape(S)[1]):\n",
    "        Error[row,col] = cost_function(y, I[row,col]+S[row,col]*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d223a4-7fea-4b4d-9a6e-3e107cedbb40",
   "metadata": {},
   "source": [
    "Then, we can visualize our best estimate on this error space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca41ee-bc31-4773-a50b-8b80c8b956a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = plt.pcolormesh(intercept_space,slope_space, np.log10(Error))\n",
    "plt.contour(intercept_space,slope_space, np.log10(Error),colors='white',linewidths=0.7)\n",
    "plt.plot(intercept_fit, slope_fit, 'wo')\n",
    "plt.text(intercept_fit+2, slope_fit, '$\\leftarrow$ Best Fit Parameters',color='white',va='center')\n",
    "plt.colorbar(C, label='log(cost)')\n",
    "plt.xlabel('intercept ($b$)')\n",
    "plt.ylabel('slope ($m$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e745792-4506-4b67-866d-4695cdd1ad1a",
   "metadata": {},
   "source": [
    "As we can see, out best fit parameters are those which minimize the error.\n",
    "\n",
    "We could also approach this as an iterative process instead of a deterministic process. In other words, if we have a guess at a set of parameters, we can use the geometry of the error space to determine the right set of parameters by making updates to our guess. To facilitate this process, we need to compute the gradient of our cost function.\n",
    "\n",
    "After we've computed the cost, we code it up in numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa329dc-c056-4d58-b182-95940356a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code up the cost_function_gradient function here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f146430-a02c-4975-b259-acb167c3765c",
   "metadata": {},
   "source": [
    "To use our cost function graident, let's make an initial guess and define a learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffa5ec-ba4c-4c3d-a688-5c49e1a6664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "intercept = 10.0 # starting intercept guess\n",
    "slope = 2.0 # starting slope guess\n",
    "weights = np.array([intercept, slope])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79f5d6-6f4b-4f37-8a22-08af5b77e34d",
   "metadata": {},
   "source": [
    "After one iteration, we can update our initial guess as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12abe34-3568-4159-8563-411d35711ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the weights using gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371de9f1-e62e-4320-a2a8-1aab0f37210c",
   "metadata": {},
   "source": [
    "We can imagine doing this over and over again until we converge on a best estimate. Let's build a slider to examine how this would look over many iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d35562-1643-4fe1-a07c-cbf78db8f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit_and_cost(initial_guess, n_iterations):\n",
    "\n",
    "    # initial_guess = np.array([10.0, 2.0])\n",
    "    # x_data = x\n",
    "    # y_data = y\n",
    "    # n_iterations = 1\n",
    "\n",
    "    weights = np.copy(initial_guess)\n",
    "    for n in range(n_iterations):\n",
    "        y_modeled = weights[0]+weights[1]*x\n",
    "        weight_gradient = cost_function_gradient(x, y, y_modeled)\n",
    "        weights -= learning_rate*weight_gradient\n",
    "    \n",
    "    fig = plt.figure(figsize=(11,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(x, y,'k.')\n",
    "    plot_x = np.linspace(np.min(x), np.max(x), 100)\n",
    "    modeled_y = weights[0] + weights[1]*plot_x\n",
    "    plt.plot(plot_x, modeled_y,'b-',\n",
    "            label='Fit: '+'{:.2f}'.format(weights[1])+'*x + ' +'{:.2f}'.format(weights[0]))\n",
    "    plt.plot(plot_x, intercept_fit + slope_fit*plot_x,'b--',\n",
    "             label='Best Fit: '+'{:.2f}'.format(slope_fit)+'*x + ' +'{:.2f}'.format(intercept_fit))\n",
    "    plt.title('Fit after '+str(n_iterations)+' iteration(s)')\n",
    "    plt.legend(loc=2)\n",
    "    plt.ylabel('y')\n",
    "    plt.xlabel('x')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    C = plt.pcolormesh(intercept_space,slope_space, np.log10(Error))\n",
    "    plt.contour(intercept_space,slope_space, np.log10(Error),colors='white',linewidths=0.7)\n",
    "    plt.plot(initial_guess[0], initial_guess[1], 'wo')\n",
    "    plt.plot(weights[0], weights[1], 'wo')\n",
    "    plt.text(initial_guess[0]+2, initial_guess[1], '$\\leftarrow$ Initial',color='white',va='center')\n",
    "    if n_iterations>0:\n",
    "        plt.text(weights[0]+2, weights[1], '$\\leftarrow$ Final',color='white',va='center')\n",
    "    plt.colorbar(C, label='log(cost)')\n",
    "    plt.title('Error space')\n",
    "    plt.ylabel('slope ($m$)')\n",
    "    plt.xlabel('intercept ($b$)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca3852-1da7-442a-a0bf-5e83be5b6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_fit_and_cost, initial_guess=fixed(np.array([intercept, slope])),\n",
    "         n_iterations=widgets.IntSlider(min=0, max=200));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce832e46-efcc-40f8-b205-f42d0206263c",
   "metadata": {},
   "source": [
    "In the above demonstration, we have \"learned\" the right parameters for our model by \"training\" it on our data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ms263-24] *",
   "language": "python",
   "name": "conda-env-ms263-24-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
